{"afb": {"batch_size": 18.0, "dropout": 0.4298255249270131, "hidden_size": 394.0, "num_layers": 2.0, "scheduler_gamma": 0.9173692920224756}, "amh": {"batch_size": 29.0, "dropout": 0.1848385399530359, "hidden_size": 395.0, "num_layers": 2.0, "scheduler_gamma": 0.9335171521459515}, "arz": {"batch_size": 27.0, "dropout": 0.2343069404580159, "hidden_size": 262.0, "num_layers": 2.0, "scheduler_gamma": 0.919061026054199}, "bel": {"batch_size": 16.0, "dropout": 0.4282303827609672, "hidden_size": 375.0, "num_layers": 1.0, "scheduler_gamma": 0.9273455040769184}, "dan": {"batch_size": 31.0, "dropout": 0.2425438772310552, "hidden_size": 426.0, "num_layers": 2.0, "scheduler_gamma": 0.9632000302778913}, "deu": {"batch_size": 34.0, "dropout": 0.4420748395599654, "hidden_size": 351.0, "num_layers": 2.0, "scheduler_gamma": 0.9156409383148388}, "eng": {"batch_size": 64.0, "dropout": 0.270023112090145, "hidden_size": 508.0, "num_layers": 2.0, "scheduler_gamma": 0.9267738155179224}, "fin": {"batch_size": 51.0, "dropout": 0.0176395502716506, "hidden_size": 428.0, "num_layers": 2.0, "scheduler_gamma": 0.9467260772263802}, "fra": {"batch_size": 8.0, "dropout": 0.2458877866810969, "hidden_size": 393.0, "num_layers": 2.0, "scheduler_gamma": 0.9278578594076664}, "grc": {"batch_size": 35.0, "dropout": 0.0960953654108003, "hidden_size": 405.0, "num_layers": 2.0, "scheduler_gamma": 0.935382972982328}, "heb": {"batch_size": 17.0, "dropout": 0.1861966402741658, "hidden_size": 209.0, "num_layers": 2.0, "scheduler_gamma": 0.9792592568440758}, "heb_unvoc": {"batch_size": 26.0, "dropout": 0.4115207257987756, "hidden_size": 282.0, "num_layers": 2.0, "scheduler_gamma": 0.9460320765663904}, "hun": {"batch_size": 20.0, "dropout": 0.0084726573041254, "hidden_size": 438.0, "num_layers": 2.0, "scheduler_gamma": 0.9472549343852904}, "hye": {"batch_size": 64.0, "dropout": 0.4174945884180798, "hidden_size": 418.0, "num_layers": 2.0, "scheduler_gamma": 0.9275092896963864}, "ita": {"batch_size": 32.0, "dropout": 0.1458080470306453, "hidden_size": 289.0, "num_layers": 2.0, "scheduler_gamma": 0.9275943602725216}, "jap": {"batch_size": 12.0, "dropout": 0.4803998704027016, "hidden_size": 450.0, "num_layers": 2.0, "scheduler_gamma": 0.9171996936483494}, "kat": {"batch_size": 11.0, "dropout": 0.0695423531675016, "hidden_size": 243.0, "num_layers": 2.0, "scheduler_gamma": 0.9557626496124996}, "klr": {"batch_size": 23.0, "dropout": 0.0181770061576676, "hidden_size": 401.0, "num_layers": 1.0, "scheduler_gamma": 0.95488067783854}, "mkd": {"batch_size": 32.0, "dropout": 0.0954655950447498, "hidden_size": 246.0, "num_layers": 2.0, "scheduler_gamma": 0.9000838958848826}, "nav": {"batch_size": 55.0, "dropout": 0.0713789116152418, "hidden_size": 387.0, "num_layers": 2.0, "scheduler_gamma": 0.9679010811272054}, "rus": {"batch_size": 57.0, "dropout": 0.1928289649009266, "hidden_size": 216.0, "num_layers": 2.0, "scheduler_gamma": 0.9316330437160104}, "sme": {"batch_size": 26.0, "dropout": 0.3313447385639002, "hidden_size": 284.0, "num_layers": 2.0, "scheduler_gamma": 0.9341597962546914}, "spa": {"batch_size": 35.0, "dropout": 0.4244445834160983, "hidden_size": 190.0, "num_layers": 2.0, "scheduler_gamma": 0.9219571614145384}, "sqi": {"batch_size": 39.0, "dropout": 0.2415275973268283, "hidden_size": 326.0, "num_layers": 2.0, "scheduler_gamma": 0.964304558167919}, "swa": {"batch_size": 45.0, "dropout": 0.3721128508514394, "hidden_size": 390.0, "num_layers": 2.0, "scheduler_gamma": 0.9124013908343408}, "tur": {"batch_size": 36.0, "dropout": 0.0619983756737565, "hidden_size": 431.0, "num_layers": 2.0, "scheduler_gamma": 0.91355842851454}}